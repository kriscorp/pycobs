{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2fafc05f-86dd-48b7-ab9d-de98e188dae1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸ“ Memproses bulan: 2025_01\n",
      "âœ… Memuat 1293954 kalimat dari output/2025\\tokenized_2025_01.csv\n",
      "ğŸ” Filter regex untuk Bahasa Indonesia...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\krisna\\AppData\\Local\\Temp\\ipykernel_6564\\3069850189.py:38: UserWarning: This pattern is interpreted as a regular expression, and has match groups. To actually get the groups, use str.extract.\n",
      "  mask = df['Sentences'].astype(str).str.lower().str.contains(pattern, regex=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ” Filter hard-rule untuk Bahasa Inggris...\n",
      "âœ… Dapat 39 kalimat Bahasa Inggris\n",
      "ğŸ’¾ Disimpan hasil gabungan: 326 kalimat â†’ output/2025\\filtered_regex_2025_01_v2.xlsx\n",
      "ğŸ‡®ğŸ‡© Filtering kalimat domestik...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Domestic Filter: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 326/326 [00:00<00:00, 54464.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Filter domestik: dari 326 â†’ 196 kalimat\n",
      "âœ… Disimpan ke: output/2025\\domestic_inflation_2025_01_v2.xlsx\n",
      "\n",
      "ğŸ“ Memproses bulan: 2025_02\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Memuat 1343941 kalimat dari output/2025\\tokenized_2025_02.csv\n",
      "ğŸ” Filter regex untuk Bahasa Indonesia...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\krisna\\AppData\\Local\\Temp\\ipykernel_6564\\3069850189.py:38: UserWarning: This pattern is interpreted as a regular expression, and has match groups. To actually get the groups, use str.extract.\n",
      "  mask = df['Sentences'].astype(str).str.lower().str.contains(pattern, regex=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ” Filter hard-rule untuk Bahasa Inggris...\n",
      "âœ… Dapat 66 kalimat Bahasa Inggris\n",
      "ğŸ’¾ Disimpan hasil gabungan: 316 kalimat â†’ output/2025\\filtered_regex_2025_02_v2.xlsx\n",
      "ğŸ‡®ğŸ‡© Filtering kalimat domestik...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Domestic Filter: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 316/316 [00:00<00:00, 70771.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Filter domestik: dari 316 â†’ 185 kalimat\n",
      "âœ… Disimpan ke: output/2025\\domestic_inflation_2025_02_v2.xlsx\n",
      "\n",
      "ğŸ“ Memproses bulan: 2025_03\n",
      "âœ… Memuat 951923 kalimat dari output/2025\\tokenized_2025_03.csv\n",
      "ğŸ” Filter regex untuk Bahasa Indonesia...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\krisna\\AppData\\Local\\Temp\\ipykernel_6564\\3069850189.py:38: UserWarning: This pattern is interpreted as a regular expression, and has match groups. To actually get the groups, use str.extract.\n",
      "  mask = df['Sentences'].astype(str).str.lower().str.contains(pattern, regex=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ” Filter hard-rule untuk Bahasa Inggris...\n",
      "âœ… Dapat 58 kalimat Bahasa Inggris\n",
      "ğŸ’¾ Disimpan hasil gabungan: 234 kalimat â†’ output/2025\\filtered_regex_2025_03_v2.xlsx\n",
      "ğŸ‡®ğŸ‡© Filtering kalimat domestik...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Domestic Filter: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 234/234 [00:00<00:00, 78235.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Filter domestik: dari 234 â†’ 129 kalimat\n",
      "âœ… Disimpan ke: output/2025\\domestic_inflation_2025_03_v2.xlsx\n",
      "\n",
      "ğŸ“ Memproses bulan: 2025_04\n",
      "âŒ File tidak ditemukan: output/2025\\tokenized_2025_04.csv\n",
      "\n",
      "ğŸ“ Memproses bulan: 2025_05\n",
      "âŒ File tidak ditemukan: output/2025\\tokenized_2025_05.csv\n",
      "\n",
      "ğŸ“ Memproses bulan: 2025_06\n",
      "âŒ File tidak ditemukan: output/2025\\tokenized_2025_06.csv\n",
      "\n",
      "ğŸ“ Memproses bulan: 2025_07\n",
      "âŒ File tidak ditemukan: output/2025\\tokenized_2025_07.csv\n",
      "\n",
      "ğŸ“ Memproses bulan: 2025_08\n",
      "âŒ File tidak ditemukan: output/2025\\tokenized_2025_08.csv\n",
      "\n",
      "ğŸ“ Memproses bulan: 2025_09\n",
      "âŒ File tidak ditemukan: output/2025\\tokenized_2025_09.csv\n",
      "\n",
      "ğŸ“ Memproses bulan: 2025_10\n",
      "âŒ File tidak ditemukan: output/2025\\tokenized_2025_10.csv\n",
      "\n",
      "ğŸ“ Memproses bulan: 2025_11\n",
      "âŒ File tidak ditemukan: output/2025\\tokenized_2025_11.csv\n",
      "\n",
      "ğŸ“ Memproses bulan: 2025_12\n",
      "âŒ File tidak ditemukan: output/2025\\tokenized_2025_12.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "# === SETUP ===\n",
    "year = 2025\n",
    "output_folder = f'output/{year}'\n",
    "keyword_file = 'keywords.txt'\n",
    "os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "# === Load daftar keyword dari file txt ===\n",
    "def load_theme_keywords_from_txt(file_path):\n",
    "    with open(file_path, 'r', encoding='utf-8') as f:\n",
    "        keywords = [line.strip() for line in f if line.strip()]\n",
    "    return keywords\n",
    "\n",
    "theme_keywords = load_theme_keywords_from_txt(keyword_file)\n",
    "\n",
    "# === Load daftar negara asing ===\n",
    "foreign_countries = [\n",
    "    \"Amerika\", \"AS\", \"Amerika Serikat\", \"USA\", \"United States\", \"global\",\n",
    "    \"China\", \"Tiongkok\", \"Trump\", \"US\", \"Vietnam\", \"Federal Reserve\", \"ECB\",\n",
    "    \"Jepang\", \"Korea\", \"Eropa\", \"Uni Eropa\", \"UE\", \"UK\", \"Inggris\", \"RBA\",\n",
    "    \"India\", \"Australia\", \"Jerman\", \"Perancis\", \"Brazil\", \"Rusia\", \"Ringgit\", \n",
    "    \"euro\", \"Georgia\", \"Beijing\", \"Iran\", \"Biden\", \"Fed\", \"Middle Eastern\",\n",
    "    \"eurozone\", \"Nasdaq\", \"PricewaterhouseCoopers\", \"Kwantas\", \"Kuala Lumpur\",\n",
    "    \"chinese\", \"european\", \"Japan\", \"Jerome Powell\", \"Canada\", \"America\", \"OPEC\",\n",
    "    \"Czech\", \"Hungary\", \"Poland\", \"BoE\", \"lira\", \"Wall Street\", \"rupee\", \"Russian\",\n",
    "    \"IMF\", \"British\", \"United Kingdom\", \"Saudi\", \"saham\", \"emiten\", \"FOMC\",\n",
    "    \"Michigan\",\"Daghlian\",\"New Zealand\",\"Filipina\",\"Bonds\",\"Federal\", \"Americans\",\n",
    "    \"Euros\", \"American\", \"BOJ\"\n",
    "]\n",
    "\n",
    "# === Fungsi filter regex (keyword Bahasa Indonesia) ===\n",
    "def filter_sentences_regex(df, keywords):\n",
    "    pattern = r'\\b(' + '|'.join(re.escape(k.lower()) for k in keywords) + r')\\b'\n",
    "    mask = df['Sentences'].astype(str).str.lower().str.contains(pattern, regex=True)\n",
    "    return df[mask].reset_index(drop=True)\n",
    "\n",
    "# === Fungsi filter Bahasa Inggris (hard rule) ===\n",
    "def has_inflation_and_expectation(text):\n",
    "    if pd.isna(text): return False\n",
    "    text = text.lower()\n",
    "    return ('inflation' in text and ('expectation' in text or 'forecast' in text or 'projection' in text))\n",
    "\n",
    "# === Fungsi filter domestik (berbasis negara asing) ===\n",
    "def should_keep_sentence(sentence, pattern):\n",
    "    if pd.isna(sentence): return True\n",
    "    sentence_lower = sentence.lower()\n",
    "    has_foreign = re.search(pattern, sentence_lower) is not None\n",
    "    has_indonesia = 'indonesia' in sentence_lower\n",
    "    return not has_foreign or (has_foreign and has_indonesia)\n",
    "\n",
    "# === Main loop untuk 1 tahun ===\n",
    "for month in range(1, 13):\n",
    "    month_str = f\"{month:02d}\"\n",
    "    file_date = f\"{year}_{month_str}\"\n",
    "\n",
    "    print(f\"\\nğŸ“ Memproses bulan: {file_date}\")\n",
    "\n",
    "    #tokenized_file = os.path.join(output_folder, f'tokenized_{file_date}.xlsx')\n",
    "    tokenized_file = os.path.join(output_folder, f'tokenized_{file_date}.csv')\n",
    "    filtered_file = os.path.join(output_folder, f'filtered_regex_{file_date}_v2.xlsx')\n",
    "    domestic_file = os.path.join(output_folder, f'domestic_inflation_{file_date}_v2.xlsx')\n",
    "\n",
    "    if not os.path.exists(tokenized_file):\n",
    "        print(f\"âŒ File tidak ditemukan: {tokenized_file}\")\n",
    "        continue\n",
    "\n",
    "    # === Step 1: Filter regex Indonesia ===\n",
    "    #df = pd.read_excel(tokenized_file)\n",
    "    df = pd.read_csv(tokenized_file)\n",
    "    print(f\"âœ… Memuat {len(df)} kalimat dari {tokenized_file}\")\n",
    "\n",
    "    print(\"ğŸ” Filter regex untuk Bahasa Indonesia...\")\n",
    "    filtered_df = filter_sentences_regex(df, theme_keywords)\n",
    "\n",
    "    # === Step 2: Filter rule Bahasa Inggris ===\n",
    "    print(\"ğŸ” Filter hard-rule untuk Bahasa Inggris...\")\n",
    "    df['keep_en'] = df['Sentences'].apply(has_inflation_and_expectation)\n",
    "    filtered_en = df[df['keep_en'] == True].drop(columns=['keep_en']).reset_index(drop=True)\n",
    "    print(f\"âœ… Dapat {len(filtered_en)} kalimat Bahasa Inggris\")\n",
    "\n",
    "    # === Step 3: Gabungkan hasil filter regex + Inggris\n",
    "    combined_df = pd.concat([filtered_df, filtered_en], ignore_index=True)\n",
    "    combined_df.to_excel(filtered_file, index=False)\n",
    "    print(f\"ğŸ’¾ Disimpan hasil gabungan: {len(combined_df)} kalimat â†’ {filtered_file}\")\n",
    "\n",
    "    # === Step 4: Filter kalimat domestik (buang asing yang tidak ada \"Indonesia\")\n",
    "    foreign_pattern = r'\\b(' + '|'.join(re.escape(fc.lower()) for fc in foreign_countries) + r')\\b'\n",
    "\n",
    "    print(\"ğŸ‡®ğŸ‡© Filtering kalimat domestik...\")\n",
    "    tqdm.pandas(desc=\"Domestic Filter\")\n",
    "    combined_df['keep'] = combined_df['Sentences'].progress_apply(lambda x: should_keep_sentence(x, foreign_pattern))\n",
    "    domestic_df = combined_df[combined_df['keep'] == True].drop(columns=['keep']).reset_index(drop=True)\n",
    "    print(f\"âœ… Filter domestik: dari {len(combined_df)} â†’ {len(domestic_df)} kalimat\")\n",
    "\n",
    "    domestic_df.to_excel(domestic_file, index=False)\n",
    "    print(f\"âœ… Disimpan ke: {domestic_file}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5c901fdf-f199-40ae-8748-69cb7e3311b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸ“ Memproses bulan: 2024_01\n",
      "âŒ File tidak ditemukan: output/2024\\tokenized_2024_01.csv\n",
      "\n",
      "ğŸ“ Memproses bulan: 2024_02\n",
      "âŒ File tidak ditemukan: output/2024\\tokenized_2024_02.csv\n",
      "\n",
      "ğŸ“ Memproses bulan: 2024_03\n",
      "âŒ File tidak ditemukan: output/2024\\tokenized_2024_03.csv\n",
      "\n",
      "ğŸ“ Memproses bulan: 2024_04\n",
      "âŒ File tidak ditemukan: output/2024\\tokenized_2024_04.csv\n",
      "\n",
      "ğŸ“ Memproses bulan: 2024_05\n",
      "âŒ File tidak ditemukan: output/2024\\tokenized_2024_05.csv\n",
      "\n",
      "ğŸ“ Memproses bulan: 2024_06\n",
      "âŒ File tidak ditemukan: output/2024\\tokenized_2024_06.csv\n",
      "\n",
      "ğŸ“ Memproses bulan: 2024_07\n",
      "âŒ File tidak ditemukan: output/2024\\tokenized_2024_07.csv\n",
      "\n",
      "ğŸ“ Memproses bulan: 2024_08\n",
      "âŒ File tidak ditemukan: output/2024\\tokenized_2024_08.csv\n",
      "\n",
      "ğŸ“ Memproses bulan: 2024_09\n",
      "âŒ File tidak ditemukan: output/2024\\tokenized_2024_09.csv\n",
      "\n",
      "ğŸ“ Memproses bulan: 2024_10\n",
      "âŒ File tidak ditemukan: output/2024\\tokenized_2024_10.csv\n",
      "\n",
      "ğŸ“ Memproses bulan: 2024_11\n",
      "âœ… Memuat 1060394 kalimat dari output/2024\\tokenized_2024_11.csv\n",
      "ğŸ” Filter regex untuk Bahasa Indonesia...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\krisna\\AppData\\Local\\Temp\\ipykernel_6564\\2295253360.py:38: UserWarning: This pattern is interpreted as a regular expression, and has match groups. To actually get the groups, use str.extract.\n",
      "  mask = df['Sentences'].astype(str).str.lower().str.contains(pattern, regex=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ” Filter hard-rule untuk Bahasa Inggris...\n",
      "âœ… Dapat 14 kalimat Bahasa Inggris\n",
      "ğŸ’¾ Disimpan hasil gabungan: 230 kalimat â†’ output/2024\\filtered_regex_2024_11_v2.xlsx\n",
      "ğŸ‡®ğŸ‡© Filtering kalimat domestik...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Domestic Filter: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 230/230 [00:00<00:00, 55441.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Filter domestik: dari 230 â†’ 157 kalimat\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Disimpan ke: output/2024\\domestic_inflation_2024_11_v2.xlsx\n",
      "\n",
      "ğŸ“ Memproses bulan: 2024_12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\krisna\\AppData\\Local\\Temp\\ipykernel_6564\\2295253360.py:73: DtypeWarning: Columns (6) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(tokenized_file)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Memuat 1059069 kalimat dari output/2024\\tokenized_2024_12.csv\n",
      "ğŸ” Filter regex untuk Bahasa Indonesia...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\krisna\\AppData\\Local\\Temp\\ipykernel_6564\\2295253360.py:38: UserWarning: This pattern is interpreted as a regular expression, and has match groups. To actually get the groups, use str.extract.\n",
      "  mask = df['Sentences'].astype(str).str.lower().str.contains(pattern, regex=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ” Filter hard-rule untuk Bahasa Inggris...\n",
      "âœ… Dapat 28 kalimat Bahasa Inggris\n",
      "ğŸ’¾ Disimpan hasil gabungan: 218 kalimat â†’ output/2024\\filtered_regex_2024_12_v2.xlsx\n",
      "ğŸ‡®ğŸ‡© Filtering kalimat domestik...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Domestic Filter: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 218/218 [00:00<00:00, 66219.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Filter domestik: dari 218 â†’ 124 kalimat\n",
      "âœ… Disimpan ke: output/2024\\domestic_inflation_2024_12_v2.xlsx\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "# === SETUP ===\n",
    "year = 2024\n",
    "output_folder = f'output/{year}'\n",
    "keyword_file = 'keywords.txt'\n",
    "os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "# === Load daftar keyword dari file txt ===\n",
    "def load_theme_keywords_from_txt(file_path):\n",
    "    with open(file_path, 'r', encoding='utf-8') as f:\n",
    "        keywords = [line.strip() for line in f if line.strip()]\n",
    "    return keywords\n",
    "\n",
    "theme_keywords = load_theme_keywords_from_txt(keyword_file)\n",
    "\n",
    "# === Load daftar negara asing ===\n",
    "foreign_countries = [\n",
    "    \"Amerika\", \"AS\", \"Amerika Serikat\", \"USA\", \"United States\", \"global\",\n",
    "    \"China\", \"Tiongkok\", \"Trump\", \"US\", \"Vietnam\", \"Federal Reserve\", \"ECB\",\n",
    "    \"Jepang\", \"Korea\", \"Eropa\", \"Uni Eropa\", \"UE\", \"UK\", \"Inggris\", \"RBA\",\n",
    "    \"India\", \"Australia\", \"Jerman\", \"Perancis\", \"Brazil\", \"Rusia\", \"Ringgit\", \n",
    "    \"euro\", \"Georgia\", \"Beijing\", \"Iran\", \"Biden\", \"Fed\", \"Middle Eastern\",\n",
    "    \"eurozone\", \"Nasdaq\", \"PricewaterhouseCoopers\", \"Kwantas\", \"Kuala Lumpur\",\n",
    "    \"chinese\", \"european\", \"Japan\", \"Jerome Powell\", \"Canada\", \"America\", \"OPEC\",\n",
    "    \"Czech\", \"Hungary\", \"Poland\", \"BoE\", \"lira\", \"Wall Street\", \"rupee\", \"Russian\",\n",
    "    \"IMF\", \"British\", \"United Kingdom\", \"Saudi\", \"saham\", \"emiten\", \"FOMC\",\n",
    "    \"Michigan\",\"Daghlian\",\"New Zealand\",\"Filipina\",\"Bonds\",\"Federal\", \"Americans\",\n",
    "    \"Euros\", \"American\", \"BOJ\"\n",
    "]\n",
    "\n",
    "# === Fungsi filter regex (keyword Bahasa Indonesia) ===\n",
    "def filter_sentences_regex(df, keywords):\n",
    "    pattern = r'\\b(' + '|'.join(re.escape(k.lower()) for k in keywords) + r')\\b'\n",
    "    mask = df['Sentences'].astype(str).str.lower().str.contains(pattern, regex=True)\n",
    "    return df[mask].reset_index(drop=True)\n",
    "\n",
    "# === Fungsi filter Bahasa Inggris (hard rule) ===\n",
    "def has_inflation_and_expectation(text):\n",
    "    if pd.isna(text): return False\n",
    "    text = text.lower()\n",
    "    return ('inflation' in text and ('expectation' in text or 'forecast' in text or 'projection' in text))\n",
    "\n",
    "# === Fungsi filter domestik (berbasis negara asing) ===\n",
    "def should_keep_sentence(sentence, pattern):\n",
    "    if pd.isna(sentence): return True\n",
    "    sentence_lower = sentence.lower()\n",
    "    has_foreign = re.search(pattern, sentence_lower) is not None\n",
    "    has_indonesia = 'indonesia' in sentence_lower\n",
    "    return not has_foreign or (has_foreign and has_indonesia)\n",
    "\n",
    "# === Main loop untuk 1 tahun ===\n",
    "for month in range(1, 13):\n",
    "    month_str = f\"{month:02d}\"\n",
    "    file_date = f\"{year}_{month_str}\"\n",
    "\n",
    "    print(f\"\\nğŸ“ Memproses bulan: {file_date}\")\n",
    "\n",
    "    #tokenized_file = os.path.join(output_folder, f'tokenized_{file_date}.xlsx')\n",
    "    tokenized_file = os.path.join(output_folder, f'tokenized_{file_date}.csv')\n",
    "    filtered_file = os.path.join(output_folder, f'filtered_regex_{file_date}_v2.xlsx')\n",
    "    domestic_file = os.path.join(output_folder, f'domestic_inflation_{file_date}_v2.xlsx')\n",
    "\n",
    "    if not os.path.exists(tokenized_file):\n",
    "        print(f\"âŒ File tidak ditemukan: {tokenized_file}\")\n",
    "        continue\n",
    "\n",
    "    # === Step 1: Filter regex Indonesia ===\n",
    "    #df = pd.read_excel(tokenized_file)\n",
    "    df = pd.read_csv(tokenized_file)\n",
    "    print(f\"âœ… Memuat {len(df)} kalimat dari {tokenized_file}\")\n",
    "\n",
    "    print(\"ğŸ” Filter regex untuk Bahasa Indonesia...\")\n",
    "    filtered_df = filter_sentences_regex(df, theme_keywords)\n",
    "\n",
    "    # === Step 2: Filter rule Bahasa Inggris ===\n",
    "    print(\"ğŸ” Filter hard-rule untuk Bahasa Inggris...\")\n",
    "    df['keep_en'] = df['Sentences'].apply(has_inflation_and_expectation)\n",
    "    filtered_en = df[df['keep_en'] == True].drop(columns=['keep_en']).reset_index(drop=True)\n",
    "    print(f\"âœ… Dapat {len(filtered_en)} kalimat Bahasa Inggris\")\n",
    "\n",
    "    # === Step 3: Gabungkan hasil filter regex + Inggris\n",
    "    combined_df = pd.concat([filtered_df, filtered_en], ignore_index=True)\n",
    "    combined_df.to_excel(filtered_file, index=False)\n",
    "    print(f\"ğŸ’¾ Disimpan hasil gabungan: {len(combined_df)} kalimat â†’ {filtered_file}\")\n",
    "\n",
    "    # === Step 4: Filter kalimat domestik (buang asing yang tidak ada \"Indonesia\")\n",
    "    foreign_pattern = r'\\b(' + '|'.join(re.escape(fc.lower()) for fc in foreign_countries) + r')\\b'\n",
    "\n",
    "    print(\"ğŸ‡®ğŸ‡© Filtering kalimat domestik...\")\n",
    "    tqdm.pandas(desc=\"Domestic Filter\")\n",
    "    combined_df['keep'] = combined_df['Sentences'].progress_apply(lambda x: should_keep_sentence(x, foreign_pattern))\n",
    "    domestic_df = combined_df[combined_df['keep'] == True].drop(columns=['keep']).reset_index(drop=True)\n",
    "    print(f\"âœ… Filter domestik: dari {len(combined_df)} â†’ {len(domestic_df)} kalimat\")\n",
    "\n",
    "    domestic_df.to_excel(domestic_file, index=False)\n",
    "    print(f\"âœ… Disimpan ke: {domestic_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43abde0c-da29-4613-bfcf-bc2062a93fc4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
